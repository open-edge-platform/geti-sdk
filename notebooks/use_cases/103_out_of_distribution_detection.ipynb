{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOD Detection using the Intel® Geti™ SDK\n",
    "\n",
    "This notebook shows the out-of-distribution (OOD) detection using the [kNN-based OOD detection](https://arxiv.org/abs/2204.06507) method for an image classification task. In this example, a classifier trained on the CUB-200-2011 dataset is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Preparing the dataset for training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Downloading and extracting the CUB-200-2011 dataset\n",
    "\n",
    "The [CUB-200-2011](https://www.vision.caltech.edu/datasets/cub_200_2011/) dataset is a dataset of 200 classes of birds. In this notebook, we use 90% of the dataset for training the classifier and the rest 10% as the test set for in-distribution. The same images with corruption (e.g. motion blurred) are used as the out-of-distribution dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "from urllib import request\n",
    "\n",
    "import splitfolders\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Provide the dataset (extracted/to be extracted) path here. If the dataset is not downloaded, it will be downloaded and extracted.\n",
    "data_dir = \"./use_cases/data/ood_detection/cub200\"\n",
    "\n",
    "# CUB-200-2011 example\n",
    "cub200_tar = os.path.join(data_dir, \"CUB_200_2011.tgz\")\n",
    "# If the dataset is not downloaded, download it\n",
    "if not os.path.exists(cub200_tar):\n",
    "    cub200_url = \"https://data.caltech.edu/records/65de6-vp158/files/CUB_200_2011.tgz\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    print(f\"Downloading dataset to {cub200_tar}\")\n",
    "    request.urlretrieve(cub200_url, cub200_tar)\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "# Extract the dataset unless it is already extracted.\n",
    "if not os.path.exists(os.path.join(data_dir, \"CUB_200_2011\")):\n",
    "    print(f\"Extracting dataset to f{os.path.join(data_dir,'CUB_200_2011')}\")\n",
    "    with tarfile.open(cub200_tar, \"r:gz\") as tar:\n",
    "        for member in tqdm(iterable=tar.getmembers(), total=len(tar.getmembers())):\n",
    "            tar.extract(member=member, path=data_dir)\n",
    "\n",
    "# Split the dataset for training and test purposes  - Split used is 80:20 and can be changed.\n",
    "# The trainset will be further split into train,val and test automatically on the Geti instance.\n",
    "dataset_dir = os.path.join(data_dir, \"CUB_200_2011_split\")\n",
    "if not os.path.exists(dataset_dir):\n",
    "    print(f\"Splitting dataset into train and test at {dataset_dir}\")\n",
    "    splitfolders.ratio(\n",
    "        os.path.join(data_dir, \"CUB_200_2011\", \"images\"),\n",
    "        output=dataset_dir,\n",
    "        seed=117,\n",
    "        ratio=(0.9, 0.1),\n",
    "        group_prefix=None,\n",
    "        move=False,\n",
    "    )\n",
    "    os.rename(os.path.join(dataset_dir, \"val\"), os.path.join(dataset_dir, \"id_test\"))\n",
    "\n",
    "print(\"Dataset ready to be used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2: Train a classifier on the Intel® Geti™ instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Creating a Geti object and authenticating it.\n",
    "For authentication, you need to have a .env file configuration file placed in the same directory of this notebook. More details [here](https://github.com/openvinotoolkit/geti-sdk/tree/main/notebooks#authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from geti_sdk.utils import get_server_details_from_env\n",
    "\n",
    "geti_server_configuration = get_server_details_from_env()\n",
    "\n",
    "from geti_sdk import Geti\n",
    "\n",
    "geti = Geti(server_config=geti_server_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 : Creating a project and uploading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from geti_sdk.annotation_readers import DirectoryTreeAnnotationReader\n",
    "\n",
    "PROJECT_NAME = \"CUB200-910\"  # Name of the project on the Geti instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the next step if the project is already created on the Geti instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "annotation_reader = DirectoryTreeAnnotationReader(\n",
    "    base_data_folder=os.path.join(dataset_dir, \"train\")\n",
    ")\n",
    "print(\n",
    "    f\"# of images for training the classifier : {len(annotation_reader.get_data_filenames())}\"\n",
    ")\n",
    "print(f\"# of classes : {len(annotation_reader.get_all_label_names())}\")\n",
    "\n",
    "\n",
    "project = geti.create_single_task_project_from_dataset(\n",
    "    project_name=PROJECT_NAME,\n",
    "    project_type=\"classification\",\n",
    "    path_to_images=os.path.join(dataset_dir, \"train\"),\n",
    "    annotation_reader=annotation_reader,\n",
    "    enable_auto_train=False,\n",
    ")\n",
    "print(project.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T12:37:04.931363700Z",
     "start_time": "2023-06-21T12:36:58.216222100Z"
    }
   },
   "source": [
    "### 2.3 Train the classifier\n",
    "We choose the EfficientNet-V2-S algorithm for training the classifier. The list of available algorithms can be obtained using the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from geti_sdk.rest_clients import ProjectClient, TrainingClient\n",
    "\n",
    "project_client = ProjectClient(session=geti.session, workspace_id=geti.workspace_id)\n",
    "project = project_client.get_project_by_name(project_name=PROJECT_NAME)\n",
    "training_client = TrainingClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "task = project.get_trainable_tasks()[0]\n",
    "available_algorithms = training_client.get_algorithms_for_task(task=task)\n",
    "print(available_algorithms.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T10:38:16.766807100Z",
     "start_time": "2023-06-20T10:09:25.210683Z"
    }
   },
   "source": [
    "Skip this step if the classifier is already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "algorithm = available_algorithms.get_by_name(name=\"EfficientNet-V2-S\")\n",
    "status = training_client.get_status()\n",
    "print(status.summary)\n",
    "\n",
    "job = training_client.train_task(\n",
    "    algorithm=algorithm,\n",
    "    task=task,\n",
    ")\n",
    "training_client.monitor_jobs([job])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T12:37:19.534902400Z",
     "start_time": "2023-06-21T12:37:18.918252700Z"
    }
   },
   "source": [
    "### 2.4 Downloading the trained classifier model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from geti_sdk.demos.demo_projects.utils import ensure_project_is_trained\n",
    "from geti_sdk.rest_clients.model_client import ModelClient\n",
    "\n",
    "# Confirm is the model is trained.\n",
    "_ = ensure_project_is_trained(geti=geti, project=project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_client = ModelClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "models = model_client.get_all_active_models()\n",
    "\n",
    "# We need the model which has xai enabled - this allows us to get the feature vector from the model.\n",
    "model_index = next(\n",
    "    (\n",
    "        index\n",
    "        for index, model in enumerate(models[0].optimized_models)\n",
    "        if model.has_xai_head\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "if model_index is None:\n",
    "    raise Exception(\n",
    "        \"No model with XAI head found! Please check if the project has such a model on the Geti instance\"\n",
    "    )\n",
    "\n",
    "model_for_deployment = models[0].optimized_models[model_index]\n",
    "model_accuracy = model_for_deployment.performance.score\n",
    "\n",
    "print(\n",
    "    f\"Model for deployment : {model_for_deployment.name} (accuracy : {model_accuracy*100:.2f} %)\"\n",
    ")\n",
    "deployment = geti.deploy_project(\n",
    "    project_name=PROJECT_NAME, models=[model_for_deployment]\n",
    ")\n",
    "deployment.load_inference_models(device=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:05:44.074454200Z",
     "start_time": "2023-06-22T08:57:27.920358700Z"
    }
   },
   "source": [
    "## 3 : Out-of-distribution dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:05:53.950164300Z",
     "start_time": "2023-06-22T09:05:49.816967600Z"
    }
   },
   "source": [
    "### 3.1: Generating the out-of-distribution dataset\n",
    "We create the out-of-distribution by applying corruptions (e.g. motion blur) on the test set of in-distribution images. The strength of the corruptions is tuned until the test set has a classification accuracy of x%, i.e., half of the test set is classified incorrectly.\n",
    "\n",
    "The possible corruptions are: `gaussian_blur`, `motion_blur`, `fake_snow`, `cut_out` and `poisson_noise`.\n",
    "\n",
    "You can set the `generate_ood_images` flag to `False` and set the `ood_images_path` to the path of the out-of-distribution images if you want to use a different set of images as OOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "id_images_path: str = os.path.join(dataset_dir, \"id_test\")\n",
    "ood_images_path: str = os.path.join(\n",
    "    dataset_dir, \"ood_test\"\n",
    ")  # Set this to the path of the OOD images if you want to use a different set of images as OOD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "generate_ood_images: bool = True\n",
    "\n",
    "if generate_ood_images:\n",
    "    from notebooks.use_cases.utils import TransformImages\n",
    "\n",
    "    transform_images = TransformImages(corruption_type=\"motion_blur\")\n",
    "    ood_images_path = transform_images.generate_ood_dataset_by_corruption(\n",
    "        geti_deployment=deployment,\n",
    "        source_path=id_images_path,\n",
    "        dest_path=ood_images_path,\n",
    "        desired_accuracy=50,\n",
    "        desired_accuracy_tol=3.0,\n",
    "        show_progress=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from notebooks.use_cases.utils import display_sample_images_in_folder\n",
    "\n",
    "display_sample_images_in_folder(\n",
    "    id_images_path, n_images=10, title=\"In-distribution images\"\n",
    ")\n",
    "display_sample_images_in_folder(\n",
    "    ood_images_path, n_images=10, title=\"Out-of-distribution images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:48:00.935602100Z",
     "start_time": "2023-06-20T12:47:56.304613900Z"
    }
   },
   "source": [
    "## 4: OOD Detection\n",
    "\n",
    "We are using a simple [kNN-based OOD detection method](https://arxiv.org/abs/2204.06507). The OOD score is calculated as the distance to the kth nearest neighbour in the feature space (of known in-distribution images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T08:24:21.893741100Z",
     "start_time": "2023-06-22T08:24:19.340621400Z"
    }
   },
   "source": [
    "### 4.1 : Calibration - Calculating the OOD score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import extract_features_from_imageclient\n",
    "\n",
    "from geti_sdk.rest_clients import ImageClient\n",
    "\n",
    "image_client = ImageClient(\n",
    "    session=geti.session, workspace_id=geti.workspace_id, project=project\n",
    ")\n",
    "\n",
    "# set the number of images to be used for calculating the OOD score threshold. The images used for training the classifier are used for calibration.\n",
    "# higher n_images_for_calib --> more accurate OOD score threshold, but also more time to get features of images\n",
    "n_images_for_calib = -1  # set to -1 to use all images\n",
    "\n",
    "features_id = extract_features_from_imageclient(\n",
    "    deployment=deployment,\n",
    "    image_client=image_client,\n",
    "    geti_session=geti.session,\n",
    "    n_images=n_images_for_calib,\n",
    "    normalise_feats=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dknn_k = 6  # number of nearest neighbours to be used for calculating the OOD score threshold. This is a hyperparameter for the DkNN OOD detection method. A number in the range of 4-10 has given good results in our experiments. Should be lower than the number of classes in the dataset.\n",
    "\n",
    "index_flat = faiss.IndexFlatL2(\n",
    "    features_id.shape[1]\n",
    ")  # Indexing the features of the ID images\n",
    "index_flat.add(features_id.astype(np.float32))\n",
    "dists, nns = index_flat.search(\n",
    "    features_id.astype(np.float32), dknn_k + 1\n",
    ")  # Calculating the distances to the k nearest neighbours among the set of ID images\n",
    "\n",
    "# Calculating the OOD score threshold\n",
    "n_percentile = 99.9\n",
    "\n",
    "# We set the distance threshold such that at least n_percentile% of known ID images are classified correctly.\n",
    "# Higher number --> more strict OOD score threshold, more true positives, but also more false positives\n",
    "ood_score_threshold = np.percentile(dists[:, dknn_k].flatten(), n_percentile)\n",
    "print(f\"OOD Threshold distance : {ood_score_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:07:51.619209300Z",
     "start_time": "2023-06-22T09:07:51.202295100Z"
    }
   },
   "source": [
    "### 4.2 : OOD Detection - Calculating the OOD scores for the ID and OOD test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from utils import extract_features_from_img_folder\n",
    "\n",
    "# test images for ID and OOD\n",
    "id_images_path = os.path.join(dataset_dir, \"id_test\")\n",
    "\n",
    "id_features = extract_features_from_img_folder(\n",
    "    deployment=deployment, images_folder_path=id_images_path, normalise_feats=True\n",
    ")\n",
    "\n",
    "ood_features = extract_features_from_img_folder(\n",
    "    deployment=deployment, images_folder_path=ood_images_path, normalise_feats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Performing the knn search with k = dknn_k\n",
    "scores_id, _ = index_flat.search(id_features.astype(np.float32), k=dknn_k)\n",
    "scores_ood, _ = index_flat.search(ood_features.astype(np.float32), k=dknn_k)\n",
    "\n",
    "# Take the highest distance --> this is the distance to the kth neighbour.\n",
    "# Taking a negative of the scores as we would want the ID images to have higher value while plotting the results\n",
    "scores_id = -scores_id[:, -1]\n",
    "scores_ood = -scores_ood[:, -1]\n",
    "\n",
    "scores_concat = np.concatenate((scores_id, scores_ood))\n",
    "ground_truth_id = np.ones(scores_id.shape[0])\n",
    "ground_truth_ood = np.zeros(scores_ood.shape[0])\n",
    "ground_truth = np.concatenate((ground_truth_id, ground_truth_ood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:07:54.418411700Z",
     "start_time": "2023-06-22T09:07:53.955948500Z"
    }
   },
   "source": [
    "## 5 : OOD Detection - Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:08:25.177320400Z",
     "start_time": "2023-06-22T09:08:17.939839400Z"
    }
   },
   "source": [
    "### 5.1 : Results - ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds_roc = metrics.roc_curve(ground_truth, scores_concat)\n",
    "precision, recall, thresholds_pr = metrics.precision_recall_curve(\n",
    "    ground_truth, scores_concat\n",
    ")\n",
    "auroc = metrics.auc(fpr, tpr)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, color=\"#003e6d\")\n",
    "plt.text(0.8, 0.3, f\"AUROC = {auroc:.4f}\", fontsize=12, ha=\"center\")\n",
    "plt.title(\"ROC \\n(ID images as positive examples)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 : Results - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "predictions = scores_concat > (-ood_score_threshold)\n",
    "confusion_matrix = metrics.confusion_matrix(ground_truth, predictions)\n",
    "ax = sns.heatmap(\n",
    "    confusion_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    ")\n",
    "ax.set_xlabel(\"Predicted\", fontsize=14, labelpad=20)\n",
    "ax.xaxis.set_ticklabels([\"(OOD)\", \"(ID)\"])\n",
    "ax.set_ylabel(\"Ground Truth\", fontsize=14, labelpad=20)\n",
    "ax.yaxis.set_ticklabels([\"(OOD)\", \"(ID)\"])\n",
    "ax.set_title(\"Confusion Matrix - ID v OOD\", fontsize=14, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Results - Displaying mis-classified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from utils import show_top_n_misclassifications\n",
    "\n",
    "# The following plot shows the overlap in scores between in- and out-of-distribution images.\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "sns.kdeplot(scores_id, fill=True, color=\"#0068b5\", label=\"ID\")\n",
    "sns.kdeplot(scores_ood, fill=True, color=\"#e96115\", label=\"OOD\")\n",
    "plt.axvline(x=-ood_score_threshold, color=\"#001220\", linestyle=\"--\")\n",
    "plt.xlabel(\"OOD Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"OOD Score Distribution\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The following figures show the top n misclassified ID and OOD images.\n",
    "show_top_n_misclassifications(\n",
    "    images_dir=id_images_path,\n",
    "    scores=scores_id,\n",
    "    type_of_samples=\"id\",\n",
    "    n_images=9,\n",
    ")\n",
    "show_top_n_misclassifications(\n",
    "    images_dir=ood_images_path,\n",
    "    scores=scores_ood,\n",
    "    type_of_samples=\"ood\",\n",
    "    n_images=9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# delete the project on the Geti instance if required (this can not be undone)\n",
    "# project_client.delete_project(project=project_name, requires_confirmation=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
